{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from os import listdir\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_brain_contour(image, plot=False):\n",
    "    \n",
    "    #import imutils\n",
    "    #import cv2\n",
    "    #from matplotlib import pyplot as plt\n",
    "    \n",
    "    # Convert the image to grayscale, and blur it slightly\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Threshold the image, then perform a series of erosions +\n",
    "    # dilations to remove any small regions of noise\n",
    "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    # Find contours in thresholded image, then grab the largest one\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    \n",
    "\n",
    "    # Find the extreme points\n",
    "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "    \n",
    "    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n",
    "    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]            \n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "        plt.tick_params(axis='both', which='both', \n",
    "                        top=False, bottom=False, left=False, right=False,\n",
    "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "        \n",
    "        plt.title('Original Image')\n",
    "            \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(new_image)\n",
    "\n",
    "        plt.tick_params(axis='both', which='both', \n",
    "                        top=False, bottom=False, left=False, right=False,\n",
    "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "\n",
    "        plt.title('Cropped Image')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_list, image_size):\n",
    "    \"\"\"\n",
    "    Read images, resize and normalize them. \n",
    "    Arguments:\n",
    "        dir_list: list of strings representing file directories.\n",
    "    Returns:\n",
    "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
    "        y: A numpy array with shape = (#_examples, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    # load all images in a directory\n",
    "    X = []\n",
    "    y = []\n",
    "    image_width, image_height = image_size\n",
    "    \n",
    "    for directory in dir_list:\n",
    "        for filename in listdir(directory):\n",
    "            # load the image\n",
    "            image = cv2.imread(directory + '\\\\' + filename)\n",
    "            # crop the brain and ignore the unnecessary rest part of the image\n",
    "            image = crop_brain_contour(image, plot=False)\n",
    "            # resize image\n",
    "            image = cv2.resize(image, dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
    "            # normalize values\n",
    "            image = image / 255.\n",
    "            # convert image to numpy array and append it to X\n",
    "            X.append(image)\n",
    "            # append a value of 1 to the target array if the image\n",
    "            # is in the folder named 'yes', otherwise append 0.\n",
    "            if directory[-3:] == 'yes':\n",
    "                y.append([1])\n",
    "            else:\n",
    "                y.append([0])\n",
    "                \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Shuffle the data\n",
    "    X, y = shuffle(X, y)\n",
    "    \n",
    "    print(f'Number of examples is: {len(X)}')\n",
    "    print(f'X shape is: {X.shape}')\n",
    "    print(f'y shape is: {y.shape}')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples is: 240\n",
      "X shape is: (240, 240, 240, 3)\n",
      "y shape is: (240, 1)\n"
     ]
    }
   ],
   "source": [
    "augmented_path = 'dummy/'\n",
    "\n",
    "# augmented data (yes and no) contains both the original and the new generated examples\n",
    "augmented_yes = augmented_path + 'yes' \n",
    "augmented_no = augmented_path + 'no'\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = (240, 240)\n",
    "\n",
    "X, y = load_data([augmented_yes, augmented_no], (IMG_WIDTH, IMG_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images(X, y, n=50):\n",
    "    \"\"\"\n",
    "    Plots n sample images for both values of y (labels).\n",
    "    Arguments:\n",
    "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
    "        y: A numpy array with shape = (#_examples, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    for label in [0,1]:\n",
    "        # grab the first n images with the corresponding y values equal to label\n",
    "        images = X[np.argwhere(y == label)]\n",
    "        n_images = images[:n]\n",
    "        \n",
    "        columns_n = 10\n",
    "        rows_n = int(n/ columns_n)\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        i = 1 # current plot        \n",
    "        for image in n_images:\n",
    "            plt.subplot(rows_n, columns_n, i)\n",
    "            plt.imshow(image[0])\n",
    "            \n",
    "            # remove ticks\n",
    "            plt.tick_params(axis='both', which='both', \n",
    "                            top=False, bottom=False, left=False, right=False,\n",
    "                           labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        label_to_str = lambda label: \"Yes\" if label == 1 else \"No\"\n",
    "        plt.suptitle(f\"Brain Tumor: {label_to_str(label)}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2):\n",
    "       \n",
    "    \"\"\"\n",
    "    Splits data into training, development and test sets.\n",
    "    Arguments:\n",
    "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
    "        y: A numpy array with shape = (#_examples, 1)\n",
    "    Returns:\n",
    "        X_train: A numpy array with shape = (#_train_examples, image_width, image_height, #_channels)\n",
    "        y_train: A numpy array with shape = (#_train_examples, 1)\n",
    "        X_val: A numpy array with shape = (#_val_examples, image_width, image_height, #_channels)\n",
    "        y_val: A numpy array with shape = (#_val_examples, 1)\n",
    "        X_test: A numpy array with shape = (#_test_examples, image_width, image_height, #_channels)\n",
    "        y_test: A numpy array with shape = (#_test_examples, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=test_size)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 168\n",
      "number of development examples = 36\n",
      "number of test examples = 36\n",
      "X_train shape: (168, 240, 240, 3)\n",
      "Y_train shape: (168, 1)\n",
      "X_val (dev) shape: (36, 240, 240, 3)\n",
      "Y_val (dev) shape: (36, 1)\n",
      "X_test shape: (36, 240, 240, 3)\n",
      "Y_test shape: (36, 1)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of development examples = \" + str(X_val.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(y_train.shape))\n",
    "print (\"X_val (dev) shape: \" + str(X_val.shape))\n",
    "print (\"Y_val (dev) shape: \" + str(y_val.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h}:{m}:{round(s,1)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_score(y_true, prob):\n",
    "    # convert the vector of probabilities to a target vector\n",
    "    y_pred = np.where(prob > 0.5, 1, 0)\n",
    "    \n",
    "    score = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    \"\"\"\n",
    "    Arugments:\n",
    "        input_shape: A tuple representing the shape of the input of the model. shape=(image_width, image_height, #_channels)\n",
    "    Returns:\n",
    "        model: A Model object.\n",
    "    \"\"\"\n",
    "    # Define the input placeholder as a tensor with shape input_shape. \n",
    "    X_input = Input(input_shape) # shape=(?, 240, 240, 3)\n",
    "    \n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((2, 2))(X_input) # shape=(?, 244, 244, 3)\n",
    "    \n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X) # shape=(?, 238, 238, 32)\n",
    "    \n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((4, 4), name='max_pool0')(X) # shape=(?, 59, 59, 32) \n",
    "    \n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((4, 4), name='max_pool1')(X) # shape=(?, 14, 14, 32)\n",
    "    \n",
    "    # FLATTEN X \n",
    "    X = Flatten()(X) # shape=(?, 6272)\n",
    "    # FULLYCONNECTED\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X) # shape=(?, 1)\n",
    "    \n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='BrainDetectionModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\thinkpad\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(IMG_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 240, 240, 3)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 244, 244, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 238, 238, 32)      4736      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalizationV1)   (None, 238, 238, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 238, 238, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pool0 (MaxPooling2D)     (None, 59, 59, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 11,137\n",
      "Trainable params: 11,073\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "log_file_name = f'brain_tumor_detection_cnn_{int(time.time())}'\n",
    "tensorboard = TensorBoard(log_dir=f'dummy-logs/{log_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "# unique file name that will include the epoch and the validation (development) accuracy\n",
    "filepath=\"cnn-parameters-improvement-{epoch:02d}-{val_acc:.2f}\"\n",
    "# save the model with the best validation (development) accuracy till now\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 168 samples, validate on 36 samples\n",
      "WARNING:tensorflow:From c:\\users\\thinkpad\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "168/168 [==============================] - 99s 592ms/sample - loss: 1.9421 - acc: 0.5238 - val_loss: 0.6767 - val_acc: 0.5556\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 94s 561ms/sample - loss: 0.9823 - acc: 0.5655 - val_loss: 0.6859 - val_acc: 0.6111\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 96s 570ms/sample - loss: 0.7050 - acc: 0.7024 - val_loss: 0.6531 - val_acc: 0.6944\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 96s 570ms/sample - loss: 0.5619 - acc: 0.7202 - val_loss: 0.6598 - val_acc: 0.6111\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 96s 572ms/sample - loss: 0.4811 - acc: 0.7560 - val_loss: 0.6654 - val_acc: 0.6111\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 96s 574ms/sample - loss: 0.4459 - acc: 0.7798 - val_loss: 0.6414 - val_acc: 0.6667\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 96s 570ms/sample - loss: 0.3780 - acc: 0.8393 - val_loss: 0.6347 - val_acc: 0.6667\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 97s 575ms/sample - loss: 0.3307 - acc: 0.8631 - val_loss: 0.6340 - val_acc: 0.6944\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 96s 572ms/sample - loss: 0.3234 - acc: 0.8810 - val_loss: 0.6250 - val_acc: 0.6944\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 96s 571ms/sample - loss: 0.2814 - acc: 0.9107 - val_loss: 0.6176 - val_acc: 0.6944\n",
      "Elapsed time: 0:16:3.9\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val), callbacks=[tensorboard, checkpoint])\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(f\"Elapsed time: {hms_string(execution_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 168 samples, validate on 36 samples\n",
      "Epoch 1/3\n",
      "168/168 [==============================] - 96s 574ms/sample - loss: 0.2854 - acc: 0.8929 - val_loss: 0.6196 - val_acc: 0.6944\n",
      "Epoch 2/3\n",
      "168/168 [==============================] - 96s 574ms/sample - loss: 0.2605 - acc: 0.9226 - val_loss: 0.6095 - val_acc: 0.6944\n",
      "Epoch 3/3\n",
      "168/168 [==============================] - 97s 575ms/sample - loss: 0.2083 - acc: 0.9524 - val_loss: 0.6045 - val_acc: 0.6667\n",
      "Elapsed time: 0:4:49.7\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=3, validation_data=(X_val, y_val), callbacks=[tensorboard, checkpoint])\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(f\"Elapsed time: {hms_string(execution_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 168 samples, validate on 36 samples\n",
      "Epoch 1/3\n",
      "168/168 [==============================] - 96s 572ms/sample - loss: 0.2113 - acc: 0.9107 - val_loss: 0.6020 - val_acc: 0.7222\n",
      "Epoch 2/3\n",
      "168/168 [==============================] - 97s 576ms/sample - loss: 0.2166 - acc: 0.9167 - val_loss: 0.6162 - val_acc: 0.6667\n",
      "Epoch 3/3\n",
      "168/168 [==============================] - 96s 574ms/sample - loss: 0.2482 - acc: 0.8869 - val_loss: 0.5959 - val_acc: 0.7222\n",
      "Elapsed time: 0:4:49.4\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=3, validation_data=(X_val, y_val), callbacks=[tensorboard, checkpoint])\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(f\"Elapsed time: {hms_string(execution_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 168 samples, validate on 36 samples\n",
      "Epoch 1/3\n",
      "168/168 [==============================] - 96s 573ms/sample - loss: 0.1962 - acc: 0.9167 - val_loss: 0.6014 - val_acc: 0.6667\n",
      "Epoch 2/3\n",
      "168/168 [==============================] - 96s 570ms/sample - loss: 0.1492 - acc: 0.9524 - val_loss: 0.5807 - val_acc: 0.7500\n",
      "Epoch 3/3\n",
      "168/168 [==============================] - 96s 573ms/sample - loss: 0.1512 - acc: 0.9702 - val_loss: 0.5910 - val_acc: 0.6944\n",
      "Elapsed time: 0:4:48.6\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=3, validation_data=(X_val, y_val), callbacks=[tensorboard, checkpoint])\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(f\"Elapsed time: {hms_string(execution_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 168 samples, validate on 36 samples\n",
      "Epoch 1/5\n",
      "168/168 [==============================] - 96s 574ms/sample - loss: 0.1336 - acc: 0.9821 - val_loss: 0.5773 - val_acc: 0.7222\n",
      "Epoch 2/5\n",
      "168/168 [==============================] - 97s 579ms/sample - loss: 0.1122 - acc: 0.9881 - val_loss: 0.5757 - val_acc: 0.7500\n",
      "Epoch 3/5\n",
      "168/168 [==============================] - 96s 572ms/sample - loss: 0.1031 - acc: 0.9940 - val_loss: 0.5803 - val_acc: 0.7222\n",
      "Epoch 4/5\n",
      "168/168 [==============================] - 96s 572ms/sample - loss: 0.1084 - acc: 0.9702 - val_loss: 0.5674 - val_acc: 0.7500\n",
      "Epoch 5/5\n",
      "168/168 [==============================] - 97s 580ms/sample - loss: 0.1005 - acc: 0.9881 - val_loss: 0.5723 - val_acc: 0.7222\n",
      "Elapsed time: 0:8:3.7\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=5, validation_data=(X_val, y_val), callbacks=[tensorboard, checkpoint])\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(f\"Elapsed time: {hms_string(execution_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "acc\n",
      "val_loss\n",
      "val_acc\n"
     ]
    }
   ],
   "source": [
    "for key in history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    \n",
    "    train_loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "    train_acc = history['acc']\n",
    "    val_acc = history['val_acc']\n",
    "    \n",
    "    # Loss\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(history) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(filepath='models/cnn-parameters-improvement-23-0.91.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 4s 106ms/sample - loss: 0.4148 - acc: 0.8333\n"
     ]
    }
   ],
   "source": [
    "loss, acc = best_model.evaluate(x=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 0.414771549610628\n",
      "Test Accuracy = 0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "print (f\"Test Loss = {loss}\")\n",
    "print (f\"Test Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "f1score = compute_f1_score(y_test, y_test_prob)\n",
    "print(f\"F1 score: {f1score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_prob = best_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.9047619047619048\n"
     ]
    }
   ],
   "source": [
    "f1score_val = compute_f1_score(y_val, y_val_prob)\n",
    "print(f\"F1 score: {f1score_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_pred)): \n",
    "        if y_actual[i]==y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y_actual[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_pred[i]==0 and y_actual[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = y_test_prob #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "y_test_prob_n = pd.DataFrame(x_scaled)\n",
    "#y_test_prob_n\n",
    "y_test_prob_b = preprocessing.binarize(y_test_prob_n,0.5)\n",
    "y_test_prob_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 0, 12, 6)\n"
     ]
    }
   ],
   "source": [
    "values_imp = perf_measure(y_test, y_test_prob_b)\n",
    "print(values_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
